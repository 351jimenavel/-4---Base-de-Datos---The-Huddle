# üìö Books To Scrape ‚Äì Data Challenge  
**The Huddle ‚Äì Penguin Academy**

Autora: Jimena Vel√°zquez  

---

## üá™üá∏ Espa√±ol

### üß† Descripci√≥n del Proyecto  
Este desaf√≠o consisti√≥ en **extraer, estructurar y analizar datos de libros** desde el sitio web [Books to Scrape](https://books.toscrape.com/), con el objetivo de construir una **base de datos relacional completa**, realizar **consultas SQL avanzadas** y explorar el **impacto de la indexaci√≥n en el rendimiento**.

El proyecto combin√≥ **web scraping legal**, **API consumption**, **limpieza de datos**, y **modelado relacional**, permitiendo integrar informaci√≥n obtenida del sitio y de APIs externas como *Open Library* y *Google Books*.

---

### üß© Tecnolog√≠as y Herramientas
- **Python** ‚Üí Web scraping y manejo de datos  
- **BeautifulSoup + Requests** ‚Üí Extracci√≥n de informaci√≥n  
- **SQLite3** ‚Üí Base de datos relacional  
- **SQLAlchemy** ‚Üí ORM para manipulaci√≥n estructurada  
- **APIs externas** ‚Üí Open Library (prueba) y Google Books (implementaci√≥n final)  
- **JSON** ‚Üí Almacenamiento intermedio de los datos  
- **Jupyter Notebook** ‚Üí An√°lisis, visualizaci√≥n y documentaci√≥n

---

### ‚öôÔ∏è Estructura del Proyecto
| Archivo / Carpeta | Descripci√≥n |
|--------------------|-------------|
| `1-scraping-bookstoscrape.ipynb` | Extrae todos los libros y categor√≠as del sitio web. |
| `2-apigooglebooks.py` | Extrae todos los libros y categor√≠as del sitio web. |
| `3-books-database.ipynb` | Crea y puebla DB |
| `4-queries.ipynb` | Contiene consultas, comparaciones con/sin √≠ndices y conclusiones. |
| `libros_scrapeados.json` | Contiene los datos brutos del scraping. |
| `autores_extraidos_openlibrary.json` | Resultados obtenidos al probar la API de Open Library (con varios autores desconocidos). |
| `autores_googlebooks.json` | Resultados finales con datos correctos desde la API de Google Books. |
| `diagram_uml.png` | Diagrama UML del modelo relacional. |

---

### üß† Ejecuci√≥n del Proyecto

#### 1Ô∏è‚É£ Clonar el repositorio
```bash
git clone https://github.com/usuario/-4---Base-de-Datos---The-Huddle.git
cd -4---Base-de-Datos---The-Huddle/entrega
```

#### 2Ô∏è‚É£ Crear entorno virtual e instalar dependencias
```bash
python -m venv venv
source venv/bin/activate     # En Linux/Mac
venv\Scripts\activate        # En Windows
pip install -r requirements.txt
```

#### 3Ô∏è‚É£ Scraping
Ejecutar el notebook `1-scraping-bookstoscrape.ipynb`
Salida esperada: `libros_scrapeados.json`

#### 4Ô∏è‚É£ Enriquecer los datos con APIs externas
- Opci√≥n A: Ejecutar la versi√≥n con Open Library dentro de api-practice (oplib.py)

Salida esperada: `autores_extraidos_openlibrary.json`

- Opci√≥n B: Ejecutar la versi√≥n final con Google Books (2-apigooglebooks.py)
```bash
python 2-apigooglebooks.py
```
Los resultados se guardan en archivos JSON separados para mantener independencia entre fuentes.

Salida esperada: `autores_googlebooks.json`

#### 5Ô∏è‚É£ Base de Datos ‚Äî abrir el notebook 3-books-database.ipynb
Crea y puebla `books_data.db` (relaciones muchos-a-muchos).

#### 6Ô∏è‚É£ Consultas/An√°lisis ‚Äî ejecutar 4-queries.ipynb
Contiene consultas, comparaciones con/sin √≠ndices y conclusiones.

---
### üß¨ Modelo Relacional

El modelo de datos implementa relaciones muchos-a-muchos entre libros y autores, adem√°s de claves for√°neas que conectan categor√≠as y ratings.

El diagrama UML muestra las entidades:
```lua
Autor  ---< LibroAutor >---  Libro  ---< Categoria
```

---
### üß≠ Flujo General del Proyecto
- Scraping: Extracci√≥n total de los libros, precios, ratings y categor√≠as.

- Almacenamiento inicial: Datos en formato JSON.

- Integraci√≥n de APIs: Prueba con Open Library (fallo parcial) ‚Üí Google Books (√©xito).

- Poblamiento de la base de datos: Inserci√≥n de libros y autores relacionados.

- An√°lisis en Notebook: Consultas SQL, tiempos, y resultados visuales.

## üá¨üáß English

# üìö Books To Scrape ‚Äì Data Challenge  
**The Huddle ‚Äì Penguin Academy**

Author: Jimena Vel√°zquez  

---


### üß† Project Overview  
This challenge consisted of **extracting, structuring, and analyzing book data** from the website [Books to Scrape](https://books.toscrape.com/), with the goal of building a **complete relational database**, performing **advanced SQL queries**, and exploring the **impact of indexing on performance**.

The project combined **legal web scraping**, **API consumption**, **data cleaning**, and **relational modeling**, allowing integration of information obtained from the site and external APIs such as *Open Library* and *Google Books*.

---

### üß© Technologies & Tools
- **Python** ‚Üí Data extraction and manipulation  
- **BeautifulSoup + Requests** ‚Üí Web scraping  
- **SQLite3** ‚Üí Relational database  
- **SQLAlchemy** ‚Üí ORM for structured manipulation  
- **External APIs** ‚Üí Open Library (test) and Google Books (final implementation)  
- **JSON** ‚Üí Intermediate data storage  
- **Jupyter Notebook** ‚Üí Analysis, visualization, and documentation  

---

### ‚öôÔ∏è Project Structure
| File / Folder | Description |
|----------------|-------------|
| `1-scraping-bookstoscrape.ipynb` | Extracts all books and categories from the website. |
| `2-apigooglebooks.py` | Integrates the data with the Google Books API. |
| `3-books-database.ipynb` | Creates and populates the database. |
| `4-queries.ipynb` | Contains SQL queries, performance comparisons (with/without indexes), and conclusions. |
| `libros_scrapeados.json` | Raw scraped data. |
| `autores_extraidos_openlibrary.json` | Results from testing the Open Library API (many unknown authors). |
| `autores_googlebooks.json` | Final author data successfully extracted via Google Books API. |
| `diagram_uml.png` | UML diagram of the relational model. |

---

### üß† How to Run the Project

#### 1Ô∏è‚É£ Clone the repository
```bash
git clone https://github.com/usuario/-4---Base-de-Datos---The-Huddle.git
cd -4---Base-de-Datos---The-Huddle/entrega
```

#### 2Ô∏è‚É£ Create a virtual environment and install dependencies
```bash
python -m venv venv
source venv/bin/activate     # On Linux/Mac
venv\Scripts\activate        # On Windows
pip install -r requirements.txt
```

#### 3Ô∏è‚É£ Scraping
Open and run the notebook `1-scraping-bookstoscrape.ipynb`
Expected output: `libros_scrapeados.json`

#### 4Ô∏è‚É£ Enrich data with external APIs
- Option A: Run the version using Open Library inside (oplib.py)

Expected output: `autores_extraidos_openlibrary.json`

- Option B: Run the final version using Google Books (2-apigooglebooks.py)
```bash
python 2-apigooglebooks.py
```
Results will be saved as separate JSON files to maintain independence between data sources.

Expected output: `autores_googlebooks.json`

#### 5Ô∏è‚É£ Database ‚Äî open the notebook `3-books-database.ipynb`
Creates and populates `books_data.db` (many-to-many relationships).

#### 6Ô∏è‚É£ Queries / Analysis ‚Äî run `4-queries.ipynb`
Includes queries, comparisons with/without indexes, and final conclusions.

---
### üß¨ Relational Model

The data model implements many-to-many relationships between books and authors, as well as foreign keys linking categories and ratings.

The UML diagram represents the entities as follows:
```lua
Author  ---< BookAuthor >---  Book  ---< Category
```

---
### üß≠ General Project Workflow
- Scraping: Extraction of all books, prices, ratings, and categories.

- Initial storage: Data saved in JSON format.

- API integration: Tested Open Library (partial failure) ‚Üí switched to Google Books (successful).

- Database population: Insertion of books and related authors.

- Analysis in Notebook: SQL queries, timing tests, and visual results.